{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7faaed8",
   "metadata": {},
   "source": [
    "# 05: Shapley Values \n",
    "\n",
    "See sections in Molnar's book on [Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html) and [SHAP](https://christophm.github.io/interpretable-ml-book/shap.html) for background information. For actual use, see the [shap package](https://github.com/slundberg/shap)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aeffc8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmlb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this code locally, then you can uncomment this to automatically\n",
    "# save the chart data in files, rather than including the data in the spec. \n",
    "\n",
    "!mkdir -p data\n",
    "alt.data_transformers.enable('json', prefix='data/altair-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea058baa",
   "metadata": {},
   "source": [
    "## Data Preparation and Modeling\n",
    "\n",
    "For this lab, we'll be using a bike rental dataset. This is a regression dataset where the goal is to predict the number of bikes that were rented at a particular day and time. This dataset is from the [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset). The data processing was guided by [Molnar's IML book](https://christophm.github.io/interpretable-ml-book/bike-data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://gist.githubusercontent.com/DanielKerrigan/f324b392dc9a58d8bd8f8d79e1101a12/raw/c3b4760c9facfac26bcab2cd7465c4cab88ef304/bike-hour.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030bdcab",
   "metadata": {},
   "source": [
    "To reduce computation times, we'll drop some of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['yr', 'mnth', 'atemp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc77501",
   "metadata": {},
   "source": [
    "We'll use the data from 2011 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['days_since_2011'] < 365].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['cnt'])\n",
    "y_train = df_train['cnt'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421be70f",
   "metadata": {},
   "source": [
    "Next we'll train a random forest model on this dataset. We'll do a grid search with cross-validation to find reasonable hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10],\n",
    "    'bootstrap': [True],\n",
    "    'max_features': ['sqrt', 1.0],\n",
    "    'max_depth': [6, 12],\n",
    "    'min_samples_split': [2, 8],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1bdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ab01b",
   "metadata": {},
   "source": [
    "## Shapley Implementation\n",
    "\n",
    "**Exercises 1:**\n",
    "\n",
    "First, we will write a function to approximately calculate a feature's Shapley value for a given instance. Our algorithm will be similar to the one that Molnar details in [Section 9.5.3.3](https://christophm.github.io/interpretable-ml-book/shapley.html#estimating-the-shapley-value).\n",
    "\n",
    "*1a)* Select a random instance from the dataframe `df`. [df.sample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html#pandas-dataframe-sample) is useful for this.\n",
    "\n",
    "*1b)* Select a random set of features, not including the feature that we are calculating the shapley value for (`feature`). [random.randrange()](https://docs.python.org/3/library/random.html#random.randrange) and [random.sample()](https://docs.python.org/3/library/random.html#random.sample) are useful for this.\n",
    "\n",
    "*1c)* Make a copy of the instance `x`. For the features randomly selected in 1b, replace the value in `x` with the value in the random instance from 1a.\n",
    "\n",
    "*1d)* Make a copy of the instance from 1c. Replace the value of `feature` with the value from the random instance from 1a.\n",
    "\n",
    "*1e)* Get the predicted values of the instances from 1c and 1d. Calculate the difference between the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df - dataframe containing the entire dataset\n",
    "x - dataframe containing a single instance\n",
    "model - trained sklearn model\n",
    "feature - the name of the feature that we are computing the Shapley value for\n",
    "iterations - number of iterations to run for\n",
    "'''\n",
    "def calculate_shapley_value(df, x, model, feature, iterations):\n",
    "    # keep track of the total from the summation\n",
    "    value = 0\n",
    "    \n",
    "    # list of features besides the one we are computing the shapley value for\n",
    "    other_features = [f for f in df.columns if f != feature]\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # 1a: get a random instance from the df\n",
    "        random_instance = df.sample()\n",
    "        \n",
    "        # 1b: select a random set of features\n",
    "        num_features_to_change = random.randrange(len(other_features))\n",
    "        features_to_change = random.sample(other_features, num_features_to_change)\n",
    "        \n",
    "        # 1c: make a copy of the instance x for the randomly selected features,\n",
    "        # replace the value of that feature in x with the value in random_instance\n",
    "        z_original = x.copy()\n",
    "        \n",
    "        for f in features_to_change:\n",
    "            z_original[f] = random_instance[f].values\n",
    "            \n",
    "        # 1d: make a copy of z_original. replace the value\n",
    "        # of feature with the value in random_instance\n",
    "        z_different = z_original.copy()\n",
    "        z_different[feature] = random_instance[feature].values\n",
    "        \n",
    "        \n",
    "        # 1e: get the predicted values for z_original and z_different.\n",
    "        # calculate the difference between them\n",
    "        pred_original = model.predict(z_original)[0]\n",
    "        pred_different = model.predict(z_different)[0]\n",
    "        difference = pred_original - pred_different\n",
    "        \n",
    "        value += difference\n",
    "        \n",
    "    # take the mean\n",
    "    return value / iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_shapley_value(X_train, X_train.iloc[[0]], model, 'hr', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a861e",
   "metadata": {},
   "source": [
    "The below `shapley_values` function calculates the shapley value of every feature for `num_instances` instances. It returns a dataframe containing the shapley values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce50d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapley_values(df, model, iterations):\n",
    "    rows = []\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        x = df.iloc[[i]]\n",
    "        \n",
    "        row = {}\n",
    "        \n",
    "        for feature in df.columns:\n",
    "            row[feature] = calculate_shapley_value(df, x, model, feature, iterations)\n",
    "            \n",
    "        rows.append(row)\n",
    "        \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = X_train.sample(100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley = shapley_values(subset, model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace0e30",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade1c94",
   "metadata": {},
   "source": [
    "### Feature Importance Bar Chart\n",
    "\n",
    "**Exercise 2:** Create a bar chart that shows the feature importance of each feature based on the shapley values.\n",
    "\n",
    "*2a)* Calculate the mean absolute values for each feature in `shapley`. The [mean](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) and [abs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.abs.html) functions will be useful. We will want a dataframe that has two columns: one for the feature and one for the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cea46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(shapley.abs().max()).reset_index()\n",
    "feature_importance.columns = ['feature', 'value']\n",
    "\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d3f6c",
   "metadata": {},
   "source": [
    "*2b)* Plot the feature importances in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feature_importance).mark_bar().encode(\n",
    "    y=alt.Y('feature', sort='-x'),\n",
    "    x=alt.X('value', title='mean absolute shapley value')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d67285",
   "metadata": {},
   "source": [
    "### Dependence Scatter Plot\n",
    "\n",
    "**Exercise 3:** For a given feature, we can create a scatterplot that shows the relationship between an instance's value for that feature (x-axis) and its shapley value for that feature (y-axis). This works as an alternative to PDPs. Complete the function below to create a dependence plot for the given feature.\n",
    "\n",
    "*3a)* Create a dataframe containing the feature values and shapley values for the given `feature`. This dataframe should have two columns: feature_value and shapley_value. Each row represents an instance.\n",
    "\n",
    "*3b)* Return a scatterplot of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dependence(instances, shapley, feature):\n",
    "    # 3a) create a dataframe containing the feature values and shapley values \n",
    "    dependence = pd.DataFrame({\n",
    "        'feature_value': instances[feature],\n",
    "        'shapley_value': shapley[feature]\n",
    "    })\n",
    "    \n",
    "    # 3b) plot the values in a scatterplot\n",
    "    return alt.Chart(dependence).mark_point().encode(\n",
    "        x=alt.X('feature_value', title=feature),\n",
    "        y='shapley_value'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567dc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dependence(subset, shapley, 'hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dependence(subset, shapley, 'temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e8f31",
   "metadata": {},
   "source": [
    "### Summary Strip Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcfbc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
