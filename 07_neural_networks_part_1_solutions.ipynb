{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7faaed8",
   "metadata": {},
   "source": [
    "# 07: Neural Networks I\n",
    "Useful resources:\n",
    "- [Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers](https://arxiv.org/pdf/1801.06889.pdf)\n",
    "- [Distill](https://distill.pub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aeffc8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmlb\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this code locally, this automatically save the chart data in files,\n",
    "# rather than including the data in the spec. You may need to comment this out on Colab.\n",
    "\n",
    "!mkdir -p data\n",
    "alt.data_transformers.enable('json', prefix='data/altair-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea058baa",
   "metadata": {},
   "source": [
    "## Data Preparation and Modeling\n",
    "\n",
    "Load the mnist dataset and take a random sample of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67891527",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pmlb.fetch_data('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_small = mnist.sample(n=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351cc64",
   "metadata": {},
   "source": [
    "Separate the feature values from the target labels. Split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aea80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist_small.drop(columns=['target']).values\n",
    "y = mnist_small['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdc483",
   "metadata": {},
   "source": [
    "Next we'll train a multi-layer perceptron on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42722396",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(512, 256))\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e915455",
   "metadata": {},
   "source": [
    "This model has 4 layers: an input layer, two hidden layers, and an output layer. The hidden layers use the ReLU activation function. The output layer uses the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc281549",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.n_layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_df = pd.DataFrame({\n",
    "    'x': np.arange(-10, 11),\n",
    "    'y': np.maximum(np.arange(-10, 11), 0)\n",
    "})\n",
    "\n",
    "alt.Chart(relu_df).mark_line().encode(\n",
    "    x='x',\n",
    "    y=alt.Y('y').title('ReLU(x)'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31e1e1",
   "metadata": {},
   "source": [
    "The `get_layer_output` function below returns the output of the model at a given layer.\n",
    "\n",
    "References:\n",
    "- [sklearn source code for generating model predictions](https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b611bf873bd5836748647221480071a87/sklearn/neural_network/_multilayer_perceptron.py#L144).\n",
    "- [sklearn source code for ReLU and softmax activations](https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b611bf873bd5836748647221480071a87/sklearn/neural_network/_base.py#L47)\n",
    "- [scipy source code for softmax](https://github.com/scipy/scipy/blob/v1.9.3/scipy/special/_logsumexp.py#L130-L223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08715df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def softmax(X):\n",
    "    return np.exp(X) / np.exp(X).sum(axis=1, keepdims=True)\n",
    "\n",
    "def get_layer_output(model, X, layer):\n",
    "    output = X\n",
    "    \n",
    "    for i in range(layer - 1):\n",
    "        z = np.dot(output, model.coefs_[i]) + model.intercepts_[i]\n",
    "        \n",
    "        if i < model.n_layers_ - 2:\n",
    "            output = relu(z)\n",
    "        else:\n",
    "            output = softmax(z)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c701cc",
   "metadata": {},
   "source": [
    "For example, we can see that getting the output of the last layer is the same as calling the model's `predict_proba` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b382f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict_proba(X_train[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layer_output(nn, X_train[0:3], nn.n_layers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62bfbb",
   "metadata": {},
   "source": [
    "Let's use t-SNE to create projections of the activations of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_activations(X_train, y_train, nn, layers):\n",
    "    tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3)\n",
    "    dfs = []\n",
    "    \n",
    "    for i in layers:\n",
    "        activations = get_layer_output(nn, X_train, i)\n",
    "        embedded = tsne.fit_transform(activations)\n",
    "        dfs.append(pd.DataFrame({\n",
    "            'x': embedded[:,0],\n",
    "            'y': embedded[:,1],\n",
    "            'layer': i,\n",
    "            'label': y_train\n",
    "        }))\n",
    "    \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361670c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded = embed_activations(X_train[0:1500], y_train[0:1500], nn, [2, 3, 4])\n",
    "df_embedded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ae923",
   "metadata": {},
   "source": [
    "**Exercise 1:** Create an embedding that compares the activations of the last three layers. This is similar to an approach that is used in the [ActiVis paper](https://arxiv.org/pdf/1704.01942.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_embedded).mark_circle().encode(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    color='label:N',\n",
    "    column='layer:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d648ae48",
   "metadata": {},
   "source": [
    "In our dataset, an image is represented as a flat numpy array of length 784 (28 x 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db4cef",
   "metadata": {},
   "source": [
    "We can use Altair to plot this image as a heatmap. The below `get_df` function takes a flat numpy array representing an image as input and returns a pandas dataframe containing the x and y coordinates and value of each pixel in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(data):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    size = int(np.sqrt(data.shape[0]))\n",
    "    x = indices % size\n",
    "    y = np.floor(indices / size)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'value': data\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa60e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_df(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e6910",
   "metadata": {},
   "source": [
    "**Exercise 2:** \n",
    "\n",
    "Finish the `plot_image` function below. The input is the numpy array for an image. The output should be an Altair chart that visualizes the image as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(x):\n",
    "    return alt.Chart(get_df(x)).mark_rect().encode(\n",
    "        x=alt.X('x:O').axis(None),\n",
    "        y=alt.Y('y:O').axis(None),\n",
    "        color=alt.Color('value').scale(range=['black', 'white'], domain=[0, 255])\n",
    "    ).properties(\n",
    "        width=250,\n",
    "        height=250\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb09f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(X_train[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022ad34",
   "metadata": {},
   "source": [
    "Last week, we covered Shapley values. We learned that Shapley values show how each feature contributes to a prediction. We can use Shapley values to create a [saliency map](https://christophm.github.io/interpretable-ml-book/pixel-attribution.html) for an image.\n",
    "\n",
    "I've modified the code from last week to work with numpy arrays instead of pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X - nd.array containing the entire dataset\n",
    "x - nd.array containing a single instance\n",
    "model - trained sklearn model\n",
    "feature - the index of the feature that we are computing the Shapley value for\n",
    "iterations - number of iterations to run for\n",
    "'''\n",
    "def calculate_shapley_value(X, x, model, feature, label, iterations):\n",
    "    # keep track of the total from the summation\n",
    "    value = 0\n",
    "    \n",
    "    n_instances, n_features = X.shape\n",
    "    \n",
    "    features = list(range(n_features))\n",
    "    \n",
    "    # list of features besides the one we are computing the shapley value for\n",
    "    other_features = features[0:feature] + features[feature + 1:]\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # 1a: get a random instance\n",
    "        random_instance = X[random.randint(0, n_instances - 1)]\n",
    "        \n",
    "        # 1b: select a random set of features\n",
    "        num_features_to_change = random.randint(0, n_features - 1)\n",
    "        features_to_change = random.sample(other_features, num_features_to_change)\n",
    "        \n",
    "        # 1c: make a copy of the instance x for the randomly selected features,\n",
    "        # replace the value of that feature in x with the value in random_instance\n",
    "        z_original = np.copy(x)\n",
    "        \n",
    "        for f in features_to_change:\n",
    "            z_original[f] = random_instance[f]\n",
    "            \n",
    "        # 1d: make a copy of z_original. replace the value\n",
    "        # of feature with the value in random_instance\n",
    "        z_different = np.copy(z_original)\n",
    "        z_different[feature] = random_instance[feature]\n",
    "        \n",
    "        \n",
    "        # 1e: get the predicted values for z_original and z_different.\n",
    "        # calculate the difference between them\n",
    "        pred_original = model.predict_proba([z_original])[0][label]\n",
    "        pred_different = model.predict_proba([z_different])[0][label]\n",
    "        difference = pred_original - pred_different\n",
    "        \n",
    "        value += difference\n",
    "        \n",
    "    # take the mean\n",
    "    return value / iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2cfd4",
   "metadata": {},
   "source": [
    "The below `shapley_values` function calculates the shapley value of every feature for the instance `x`. It returns a flat numpy array containing the Shapley values for the given instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f58ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapley_values(X, x, model, label, iterations):\n",
    "    values = []\n",
    "    \n",
    "    for feature in list(range(X.shape[1])):\n",
    "        values.append(calculate_shapley_value(X, x, model, feature, label, iterations))\n",
    "            \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed64768",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = shapley_values(X=X_train, x=X_train[9], model=nn, label=y_train[9], iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee87bf42",
   "metadata": {},
   "source": [
    "**Exercise 3:** Finish the `plot_saliency` function below. The input is a flat numpy array containing the Shapley values for an instance. This function should return an Altair chart that plots a saliency map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab2a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_saliency(x):\n",
    "    return alt.Chart(get_df(x)).mark_rect().encode(\n",
    "        x=alt.X('x:O').axis(None),\n",
    "        y=alt.Y('y:O').axis(None),\n",
    "        color=alt.Color('value').scale(scheme='blueorange', domainMid=0)\n",
    "    ).properties(\n",
    "        width=250,\n",
    "        height=250\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e334a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency(saliency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83d4e2",
   "metadata": {},
   "source": [
    "**Exercise 4:** Finish the `plot_image_and_saliency` function below. `image` and `saliency` are both numpy arrays. The function should return an Altair chart that shows the image side-by-side the saliency map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_saliency(image, saliency):\n",
    "    return (plot_image(image) | plot_saliency(saliency)).resolve_scale(color='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b682e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_image_and_saliency(X_train[9], saliency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f5372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
