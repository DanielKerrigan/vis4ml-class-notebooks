{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7faaed8",
   "metadata": {},
   "source": [
    "# 08: Neural Networks II\n",
    "Useful resources:\n",
    "- [Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers](https://arxiv.org/pdf/1801.06889.pdf)\n",
    "- [Distill](https://distill.pub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aeffc8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmlb\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this code locally, this automatically save the chart data in files,\n",
    "# rather than including the data in the spec. You may need to comment this out on Colab.\n",
    "\n",
    "!mkdir -p data\n",
    "alt.data_transformers.enable('json', prefix='data/altair-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea058baa",
   "metadata": {},
   "source": [
    "## Data Preparation and Modeling\n",
    "\n",
    "Load the mnist dataset and take a random sample of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67891527",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pmlb.fetch_data('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_small = mnist.sample(n=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351cc64",
   "metadata": {},
   "source": [
    "Separate the feature values from the target labels. Split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aea80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist_small.drop(columns=['target']).values\n",
    "y = mnist_small['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdc483",
   "metadata": {},
   "source": [
    "Next we'll train a multi-layer perceptron on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42722396",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(512, 256))\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31140c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24119851",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12365ffc",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e915455",
   "metadata": {},
   "source": [
    "This model has 4 layers: an input layer, two hidden layers, and an output layer. The hidden layers use the ReLU activation function. The output layer uses the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc281549",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.n_layers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31e1e1",
   "metadata": {},
   "source": [
    "The `get_layer_output` function below returns the output of the model at a given layer.\n",
    "\n",
    "References:\n",
    "- [sklearn source code for generating model predictions](https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b611bf873bd5836748647221480071a87/sklearn/neural_network/_multilayer_perceptron.py#L144).\n",
    "- [sklearn source code for ReLU and softmax activations](https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b611bf873bd5836748647221480071a87/sklearn/neural_network/_base.py#L47)\n",
    "- [scipy source code for softmax](https://github.com/scipy/scipy/blob/v1.9.3/scipy/special/_logsumexp.py#L130-L223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08715df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def softmax(X):\n",
    "    return np.exp(X) / np.exp(X).sum(axis=1, keepdims=True)\n",
    "\n",
    "def get_layer_output(model, X, layer):\n",
    "    output = X\n",
    "    \n",
    "    for i in range(layer - 1):\n",
    "        z = np.dot(output, model.coefs_[i]) + model.intercepts_[i]\n",
    "        \n",
    "        if i < model.n_layers_ - 2:\n",
    "            output = relu(z)\n",
    "        else:\n",
    "            output = softmax(z)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c701cc",
   "metadata": {},
   "source": [
    "For example, we can see that getting the output of the last layer is the same as calling the model's `predict_proba` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b382f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict_proba(X_train[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layer_output(nn, X_train[0:3], nn.n_layers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8bc43f",
   "metadata": {},
   "source": [
    "## Neuron Activation Matrix\n",
    "\n",
    "The [ActiVis paper](https://arxiv.org/pdf/1704.01942.pdf) contains a neuron activation matrix. Each row in the matrix represents a subset of instances. Each column represents a neuron in the neural network. Let's create a version of this matrix for our model. We will subset the instances by their true class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a4217",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "First, we need a function that computes the average activation for each hidden neuron in our model for a given set of instances. This function should return a flat list of the average activations for the neurons in the hidden layers. In our case, there are two hidden layers with a combined total of 768 neurons, so this list should contain 768 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X - 2D numpy array representing a set of instances\n",
    "nn - sklearn MLPClassifier\n",
    "'''\n",
    "def get_average_activations(X, nn):\n",
    "    activations = []\n",
    "    \n",
    "    for layer in range(2, nn.n_layers_):\n",
    "        activations.extend(get_layer_output(nn, X, layer).mean(axis=0))\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be993ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_average_activations(X_test[y_test == 0], nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd527d3",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "Next, we need a function that puts the average activations for each subset of instances into a single dataframe. We will split the instances into subsets based on their ground-truth label. Each row of the dataframe will represent a pair of an instance subset and a neuron (i.e. each row is one cell in the matrix). The dataframe will have three columns:\n",
    "- \"neuron\" for the index of the neuron\n",
    "- \"label\" for the label of the instances in the subset\n",
    "- \"activation\" for the average activation of the neuron for the instances in the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X - 2D numpy array containing the instances\n",
    "y - 1D numpy array containing the ground-truth labels\n",
    "nn - sklearn MLPClassifier\n",
    "'''\n",
    "def calculate_activation_matrix(X, y, nn):\n",
    "    dfs = []\n",
    "    \n",
    "    # 2a: get a list of the unique labels\n",
    "    classes = sorted(list(set(y)))\n",
    "    \n",
    "    # 2b: we'll refer to the neurons by their index in the lists returned\n",
    "    # by get_average_activations. for convenience, we'll get the list of\n",
    "    # neuron indices here (i.e. [0, 1, 2, 3, ..., 766, 767])\n",
    "    num_neurons = sum(nn.hidden_layer_sizes)\n",
    "    neuron_ids = list(range(num_neurons))\n",
    "    \n",
    "    for label in classes:\n",
    "        # 2c: get the average activation for the instances with this label\n",
    "        activations = get_average_activations(X[y == label], nn)\n",
    "        \n",
    "        # 2d: create a dataframe for this subset\n",
    "        df = pd.DataFrame({\n",
    "            'neuron': neuron_ids,\n",
    "            'label': label,\n",
    "            'activation': activations\n",
    "        })\n",
    "        \n",
    "        dfs.append(df)\n",
    "        \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441dbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = calculate_activation_matrix(X_test, y_test, nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75660de",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5d569",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "\n",
    "768 neurons is too many to show at once. In the ActiVis paper, you can choose the neurons that have the highest activations for a given class. Complete the `get_top_neurons` function below. It should return a sorted list of the top `num_neurons` neurons that have the highest average activation for the subsets with the given `label`. If no label is passed, then it should return the top neurons that have the highest average activation across all subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "activations - pandas dataframe\n",
    "num_neurons - number of neurons to take\n",
    "subset - label of the subset of instances to sort the neurons by\n",
    "'''\n",
    "def get_top_neurons(activations, num_neurons, subset=None):\n",
    "    if subset is not None:\n",
    "        activations = activations[activations[\"label\"] == subset]\n",
    "    mean_by_neuron = activations.groupby('neuron')[['activation']].mean()\n",
    "    top_neurons = mean_by_neuron.sort_values('activation', ascending=False).index[0:num_neurons]\n",
    "    return list(top_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d93f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dde6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons_0 = get_top_neurons(activations, num_neurons, 0)\n",
    "top_neurons_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a4b4d",
   "metadata": {},
   "source": [
    "**Exercise 4:**\n",
    "\n",
    "Once we've computed a sorted list of `neurons`, we need a function that will filter the `activations` dataframe to only contain those neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7493f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "activations - pandas dataframe\n",
    "neurons - list containing indices of neurons\n",
    "'''\n",
    "def filter_activations(activations, neurons):\n",
    "    return activations[activations['neuron'].isin(neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88163712",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_activations(activations, top_neurons_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e3126",
   "metadata": {},
   "source": [
    "**Exercise 5:**\n",
    "\n",
    "Complete the `neuron_activation_matrix` function below. It should return a heatmap of the activations for the top `num_neurons` for the given `label`. You should call `get_top_neurons` and `filter_activations` in this function.\n",
    "\n",
    "Note: the heatmap will still have one row per label. The `label` argument determines which subset of instances is used to sort the neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "activations - pandas dataframe\n",
    "num_neurons - number of neurons (columns) to show in the matrix\n",
    "label - subset of instances to sort the neurons by\n",
    "'''\n",
    "def neuron_activation_matrix(activations, num_neurons, label):\n",
    "    neurons = get_top_neurons(activations, num_neurons, label)\n",
    "    activations = filter_activations(activations, neurons)\n",
    "    return alt.Chart(activations).mark_rect().encode(\n",
    "        x=alt.X('neuron:N').sort(neurons),\n",
    "        y='label:N',\n",
    "        color='activation'\n",
    "    ).properties(\n",
    "        title=f'top {num_neurons} neurons sorted by activation for label {label}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf086eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_activation_matrix(activations, num_neurons, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2e2aa",
   "metadata": {},
   "source": [
    "**Exercise 6:**\n",
    "\n",
    "Concatenate the neuron activation matrices sorted by each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "activations - pandas dataframe\n",
    "num_neurons - number of columns in each matrix\n",
    "labels - list of numbers\n",
    "'''\n",
    "def all_neuron_activation_matrices(activations, num_neurons, labels):\n",
    "    charts = [neuron_activation_matrix(activations, num_neurons, label) for label in labels]\n",
    "    return alt.vconcat(*charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ee6b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_neuron_activation_matrices(activations, num_neurons, range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d06fdf",
   "metadata": {},
   "source": [
    "**Exercise 7:** Make a confusion matrix for this model's test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f3a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f45097",
   "metadata": {},
   "source": [
    "Confusion matrix with zeros \\[[1](https://stackoverflow.com/a/42854842/5016634)\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame({\n",
    "    'target': y_test,\n",
    "    'prediction': y_pred\n",
    "}).groupby(['target', 'prediction']).size().unstack(fill_value=0).stack().reset_index()\n",
    "\n",
    "cm.rename(columns={0: 'size'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(cm).encode(\n",
    "    x=alt.X('prediction:N').title('predicted class').axis(labelAngle=0),\n",
    "    y=alt.Y('target:N').title('actual class'),\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "rect = base.mark_rect().encode(\n",
    "    color=alt.Color('prediction:N').legend(None),\n",
    "    opacity=alt.Opacity('size').scale(range=[0, 1], type='symlog').legend(None),\n",
    ")\n",
    "\n",
    "text = base.mark_text().encode(\n",
    "    text='size',\n",
    ")\n",
    "\n",
    "rect + text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb19ed8",
   "metadata": {},
   "source": [
    "**Exercise 8:**\n",
    "\n",
    "We don't have to just subset the instances by their ground truth label. For example, we can subset the labels by their ground truth and predicted label. For example, we can see that our model misclassifies 9's as 4's relatively often. Let's create an activation matrix for four subsets of instances:\n",
    "- true label 9, predicted label 9\n",
    "- true label 4, predicted label 9\n",
    "- true label 4, predicted label 4\n",
    "- true label 9, predicted label 4\n",
    "\n",
    "If your model makes a different kind of error more often, then feel free to use those labels.\n",
    "\n",
    "Complete the function below to compute the activations for these subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_of_interest = [4, 9]\n",
    "pairs = list(product(labels_of_interest, repeat=2))\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X - 2D numpy array containing the instances\n",
    "y_true - 1D numpy array containing the ground-truth labels\n",
    "y_pred - 1D numpy array containing the predicted labels\n",
    "nn - sklearn MLPClassifier\n",
    "subsets - list of tuples in the format (true label, predicted label)\n",
    "'''\n",
    "def calculate_activation_matrix_errors(X, y_true, y_pred, nn, subsets):\n",
    "    dfs = []\n",
    "    \n",
    "    num_neurons = sum(nn.hidden_layer_sizes)\n",
    "    neuron_ids = list(range(num_neurons))\n",
    "    \n",
    "    for (true_label, pred_label) in subsets:\n",
    "        subset = X[(y_true == true_label) & (y_pred == pred_label)]\n",
    "        activations = get_average_activations(subset, nn)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'neuron': neuron_ids,\n",
    "            'subset': f'pred={pred_label},true={true_label}',\n",
    "            'activation': activations\n",
    "        })\n",
    "        \n",
    "        dfs.append(df)\n",
    "        \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_errors = calculate_activation_matrix_errors(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    nn,\n",
    "    pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe721734",
   "metadata": {},
   "source": [
    "**Exercise 9:**\n",
    "\n",
    "Complete the function below to create a heatmap for these activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eae963",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "activations - pandas dataframe\n",
    "num_neurons - number of neurons (columns) to show in the matrix\n",
    "'''\n",
    "def neuron_activation_matrix_errors(activations, num_neurons):\n",
    "    neurons = get_top_neurons(activations, num_neurons)\n",
    "    activations = filter_activations(activations, neurons)\n",
    "    return alt.Chart(activations).mark_rect().encode(\n",
    "        x=alt.X('neuron:N').sort(neurons),\n",
    "        y='subset',\n",
    "        color='activation'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_activation_matrix_errors(activations_errors, num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2422bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
