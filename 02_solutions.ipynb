{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this on colab, then you can uncomment the bellow command to\n",
    "# install the pmlb library.\n",
    "# !pip install pmlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmlb\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this code locally, then you can uncomment this to automatically\n",
    "# save the chart data in files, rather than including the data in the spec. \n",
    "\n",
    "# !mkdir -p data\n",
    "# alt.data_transformers.enable('json', prefix='data/altair-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80358a",
   "metadata": {},
   "source": [
    "## Date Preparation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ed763",
   "metadata": {},
   "source": [
    "For this lab, we'll be using a dataset about a telephone service provider's customers. Each instance is a customer. The target is whether or not the customer churns, or switches providers. We load it from [Penn Machine Learning Benchmarks](https://epistasislab.github.io/pmlb/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2009469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pmlb.fetch_data('churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2faed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ea9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7c2c0",
   "metadata": {},
   "source": [
    "In preparation for modeling this dataset, we split the dataset into a train and test set and separate the instances from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39069c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bb0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['target'])\n",
    "y_train = df_train['target'].values\n",
    "\n",
    "X_test = df_test.drop(columns=['target'])\n",
    "y_test = df_test['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b93ec7",
   "metadata": {},
   "source": [
    "Before we train a model, let's explore the training dataset first.\n",
    "\n",
    "**Exercise 1:** Create a visualization that compares the number of customers who churned vs. did not churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_bar().encode(\n",
    "    x='target:O',\n",
    "    y='count()'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d12ce",
   "metadata": {},
   "source": [
    "**Exercise 2:** Create a histogram for each feature. Are there any improvements that could make the histograms more usfeul?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20972433",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = []\n",
    "\n",
    "for feature in features:\n",
    "    histogram = alt.Chart(df_train).mark_bar().encode(\n",
    "        x=alt.X(feature, bin=True),\n",
    "        y=alt.Y('count()')\n",
    "    )\n",
    "\n",
    "    histograms.append(histogram)\n",
    "\n",
    "alt.hconcat(*histograms).resolve_scale(y='shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c161b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_bar().encode(\n",
    "    x=alt.X(alt.repeat('column'), bin=True, type='quantitative'),\n",
    "    y=alt.Y('count()'),\n",
    "    color='target:N'\n",
    ").repeat(\n",
    "    column=features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15bb457",
   "metadata": {},
   "source": [
    "**Exercise 3:** Create a [scattplot matrix](https://observablehq.com/@d3/splom) for the subset of features selected below. What insights can you make from these plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_subset = [f for f in features if 'total day' in f] + ['number customer service calls', 'number vmail messages']\n",
    "features_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bd350",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_point().encode(\n",
    "    x=alt.X(alt.repeat('column'), type='quantitative'),\n",
    "    y=alt.Y(alt.repeat('row'), type='quantitative'),\n",
    "    color='target:N'\n",
    ").properties(\n",
    "    width=120,\n",
    "    height=120\n",
    ").repeat(\n",
    "    column=features_subset,\n",
    "    row=features_subset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a3a8e",
   "metadata": {},
   "source": [
    "**Exercise 4**: Here we have one of the scatterplots from above. It is suffering from overplotting, making it hard to reason about how these two features impact the target. Try to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_point().encode(\n",
    "    x='total day calls',\n",
    "    y='total day minutes',\n",
    "    color='target:N',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_point().encode(\n",
    "    x='total day calls',\n",
    "    y='total day minutes',\n",
    "    color='target:N',\n",
    "    column='target:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_rect().encode(\n",
    "    x=alt.X('total day calls', bin=alt.Bin(maxbins=20)),\n",
    "    y=alt.Y('total day minutes', bin=alt.Bin(maxbins=20)),\n",
    "    color='mean(target)',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25990ceb",
   "metadata": {},
   "source": [
    "**Exercise 5:** \"total day minutes\" and \"total day charge\" are perfectly correlated. Is the same true for \"total eve minutes\" and \"total eve charge\" and for \"total night minutes\" and \"total night charge\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_point().encode(\n",
    "    x=alt.X('total eve charge'),\n",
    "    y=alt.Y('total eve minutes'),\n",
    "    color='target:N',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89833e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_train).mark_point().encode(\n",
    "    x=alt.X('total night charge'),\n",
    "    y=alt.Y('total night minutes'),\n",
    "    color='target:N',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d10aeb",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "To start, we'll remove the charge features from the dataset, since they are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ec918",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['total day charge', 'total eve charge', 'total night charge'], inplace=True)\n",
    "X_test.drop(columns=['total day charge', 'total eve charge', 'total night charge'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a26a7",
   "metadata": {},
   "source": [
    "We will use [scikit-learn](https://scikit-learn.org/stable/) to train a random forest model on this dataset. Below is an example of performing a grid search and cross validation to find reasonable hyperparameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [True],\n",
    "    'max_features': ['sqrt', 1.0],\n",
    "    'max_depth': [6, 12],\n",
    "    'min_samples_split': [2, 8],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, scoring='f1', n_jobs=-1)\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b02809",
   "metadata": {},
   "source": [
    "We can see what the best parameters are and what the corresponding F1 score for those parameters is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02400293",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfbe0f",
   "metadata": {},
   "source": [
    "As a basic sanity check, we can use the model's built-in feature importance score to check if the most important features match what we expect from our exploration and intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441add1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19512e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(model.feature_importances_, X_train.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fffd54",
   "metadata": {},
   "source": [
    "Next, we use our model to generate predictions on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e13a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00fe9f1",
   "metadata": {},
   "source": [
    "## Confusion Matrices\n",
    "\n",
    "sklearn has functions that let us [calculate](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and [plot](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay) a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33494b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8248d6a",
   "metadata": {},
   "source": [
    "Rather than relying on those, let's compute and plot the confusion matrix on our own.\n",
    "\n",
    "**Exercise 6:** Calculate the confusion matrix. We want a pandas dataframe that will look similar to this, except not hard-coded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95701b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame({\n",
    "    'target': [0, 0, 1, 1],\n",
    "    'prediction': [0, 1, 0, 1],\n",
    "    'size': [1080, 12, 45, 113]\n",
    "})\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06edbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = df_test.groupby(['target', 'prediction'], as_index=False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460fdaf",
   "metadata": {},
   "source": [
    "From this data, we can create a confusion matrix that looks similar to the standard one from [this paper by Hong Shen et al.](https://www.andrew.cmu.edu/user/hongs/files/CM_CSCW2020.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e322e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values 0 and 1 with negative and positive\n",
    "cm_pn = cm.replace({0: 'negative', 1: 'positive'})\n",
    "\n",
    "alt.Chart(cm_pn).mark_text().encode(\n",
    "    x=alt.X('prediction:N', title='predicted class'),\n",
    "    y=alt.Y('target:N', title='actual class'),\n",
    "    text='size'\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c69a10",
   "metadata": {},
   "source": [
    "**Exercise 7**: Create a confusion matrix that looks similar to the contextualized confusion matrix from the above paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rc = cm.replace({0: 'retained', 1: 'churned'})\n",
    "\n",
    "base = alt.Chart(cm_rc).encode(\n",
    "    x=alt.X('prediction:N', title='predicted class', axis=alt.Axis(labelAngle=0)),\n",
    "    y=alt.Y('target:N', title='actual class'),\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "rect = base.mark_rect().encode(\n",
    "    color=alt.Color('prediction', legend=None),\n",
    "    opacity=alt.Opacity('size', legend=None),\n",
    ")\n",
    "\n",
    "text = base.mark_text().encode(\n",
    "    text='size',\n",
    ")\n",
    "\n",
    "rect + text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bba16",
   "metadata": {},
   "source": [
    "**Exercise 8**: In class, we noted how this visualization could possibly be improved by using the size of the squares to encode the number of instances. Implement that below.\n",
    "\n",
    "Tips:\n",
    "- You'll want to change your mark from `mark_rect` to `mark_square`, so that you can more easily set the size.\n",
    "- You'll want to change the width and height to be based on the step size of the scale. See the intro to Altair notebook for an example of how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa36554",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rc = cm.replace({0: 'retained', 1: 'churned'})\n",
    "\n",
    "base = alt.Chart(cm_rc).encode(\n",
    "    x=alt.X('prediction:N', title='predicted class'),\n",
    "    y=alt.Y('target:N', title='actual class'),\n",
    ").properties(\n",
    "    width={'step': 100},\n",
    "    height={'step': 100}\n",
    ")\n",
    "\n",
    "rect = base.mark_square().encode(\n",
    "    color=alt.Color('prediction', legend=None),\n",
    "    opacity=alt.Opacity('size', legend=None),\n",
    "    size='size:Q'\n",
    ")\n",
    "\n",
    "text = base.mark_text().encode(\n",
    "    text='size',\n",
    ")\n",
    "\n",
    "rect + text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f489c51",
   "metadata": {},
   "source": [
    "#### Faceting Layered Charts\n",
    "\n",
    "Previously when we covered faceting, we used the \"row\", \"column\", or \"facet\" encodings. In order to facet layered charts, we need to do things a bit differently. We need to do the faceting after the layering. Let's make a faceted lollipop chart that compares the distribution of number of customer service calls for customers that did and did not churn.\n",
    "\n",
    "Faceting before layering does not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba24260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = alt.Chart(df_train).encode(\n",
    "    x='number customer service calls:O',\n",
    "    y='count()',\n",
    "    column='target'\n",
    ")\n",
    "\n",
    "base.mark_circle() + base.mark_rule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d8fa7",
   "metadata": {},
   "source": [
    "Instead, we use the `facet()` after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(df_train).encode(\n",
    "    x='number customer service calls:O',\n",
    "    y='count()',\n",
    ")\n",
    "\n",
    "(base.mark_rule() + base.mark_circle()).facet(column='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1038351c",
   "metadata": {},
   "source": [
    "**Exercise 9:** Implement the bar chart confusion matrix design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf25ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rc = cm.replace({0: 'retained', 1: 'churned'})\n",
    "\n",
    "base = alt.Chart(cm_rc).encode(\n",
    "    x=alt.X('prediction:N', title='predicted class'),\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=100\n",
    ")\n",
    "\n",
    "rect = base.mark_bar().encode(\n",
    "    color=alt.Color('prediction', legend=None),\n",
    "    y=alt.Y('size', axis=None),\n",
    "    opacity=alt.Opacity('size', legend=None),\n",
    ")\n",
    "\n",
    "text = base.mark_text(baseline='bottom').encode(\n",
    "    y='size',\n",
    "    text='size',\n",
    ")\n",
    "\n",
    "(rect + text).facet(\n",
    "    row=alt.Row('target:N', title='actual class')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3eb054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
