{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7faaed8",
   "metadata": {},
   "source": [
    "# 03: PDPs and ICE Plots\n",
    "\n",
    "Partial dependence plots (PDPs) and individual conditional expectation (ICE) plots are common techniques for model explainability. They show the impact that a feature or pair of features has on a model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342601b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this on colab, then you can uncomment the below command to\n",
    "# install the pmlb library.\n",
    "# !pip install pmlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from itertools import product\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmlb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this code locally, then you can uncomment this to automatically\n",
    "# save the chart data in files, rather than including the data in the spec. \n",
    "\n",
    "# !mkdir -p data\n",
    "# alt.data_transformers.enable('json', prefix='data/altair-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea058baa",
   "metadata": {},
   "source": [
    "## Data Preparation and Modeling\n",
    "\n",
    "For this lab, we'll be using the same dataset from the second lab about a telephone service provider's customers. Each instance is a customer. The target is whether or not the customer churns, or switches providers. We'll drop the columns we previously found to be redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d327b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pmlb.fetch_data('churn')\n",
    "df.drop(columns=['total day charge', 'total eve charge', 'total night charge'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc77501",
   "metadata": {},
   "source": [
    "In preparation for modeling this dataset, we split the dataset into a train and test set and separate the instances from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['target'])\n",
    "y_train = df_train['target'].values\n",
    "\n",
    "X_test = df_test.drop(columns=['target'])\n",
    "y_test = df_test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [True],\n",
    "    'max_features': ['sqrt', 1.0],\n",
    "    'max_depth': [6, 12],\n",
    "    'min_samples_split': [2, 8],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, scoring='f1', n_jobs=-1)\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1bdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8db48a",
   "metadata": {},
   "source": [
    "## One-way Partial Dependence and ICE Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc9ca1",
   "metadata": {},
   "source": [
    "### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X=X_train,\n",
    "    features=['total day minutes'],\n",
    "    kind='both',\n",
    "    grid_resolution=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00289373",
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X=X_train,\n",
    "    features=['total day minutes'],\n",
    "    kind='average',\n",
    "    grid_resolution=20,\n",
    "    percentiles=(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c3cdb",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "**Exercises 1-3:**\n",
    "\n",
    "First, we will write a function to calculate the partial dependence and ICE lines for a list of features. The output of this function will be a dictionary that maps from the name of the feature to a `FeatureData` instance. We'll do this in 4 steps.\n",
    "\n",
    "1. Calculate the values for the feature that we will evaluate the model at. `resolution` is the number of points we want to sample. [`np.linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) might be helpful.\n",
    "2. Calculate the ICE lines. To do this, you'll need to loop over the values, set all instances to have that value for the feature, and have the model generate probabilities for those instances.\n",
    "3. Calculate the partial dependence line. This is the mean of the ICE lines. Also calculate the mean-centered partial dependence line by making the partial dependence line have a mean of 0. Create a `FeatureData` instance and add it to the `one_way_data` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureData:\n",
    "    # name of the feature\n",
    "    feature: str\n",
    "    \n",
    "    # 1D array of feature values that we will check the model at\n",
    "    values: np.ndarray\n",
    "    \n",
    "    # 2D array of the ICE lines. The shape will be (number of instances, number of features)\n",
    "    ice: np.ndarray\n",
    "    \n",
    "    # 1D array containing the partial dependence\n",
    "    pd: np.ndarray\n",
    "    \n",
    "    # 1D array containing the mean-centered partial dependence\n",
    "    mean_centered_pd: np.ndarray\n",
    "            \n",
    "def calculate_one_way(df, model, features, resolution):\n",
    "    one_way_data = {}\n",
    "\n",
    "    for feature in features:\n",
    "        # 1\n",
    "        values = np.linspace(df[feature].min(), df[feature].max(), num=resolution)\n",
    "\n",
    "        # 2\n",
    "        ice = []\n",
    "\n",
    "        original_values = df[feature]\n",
    "\n",
    "        for x in values:\n",
    "            df[feature] = x\n",
    "            predictions = model.predict_proba(df)[:,1]\n",
    "            ice.append(predictions)\n",
    "\n",
    "        ice = np.array(ice).T\n",
    "\n",
    "        df[feature] = original_values\n",
    "\n",
    "        # 3\n",
    "        pd = ice.mean(axis=0)\n",
    "        mean_centered_pd = pd - pd.mean()\n",
    "\n",
    "        one_way_data[feature] = FeatureData(feature, values, ice, pd, mean_centered_pd)\n",
    "    \n",
    "    return one_way_data\n",
    "\n",
    "# for simplicity, we'll remove categorical features\n",
    "categories = ['state', 'area code', 'phone number', 'international plan', 'voice mail plan']\n",
    "features = [f for f in X_train.columns if f not in categories]\n",
    "one_way_data = calculate_one_way(X_train, model, features, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_way_data['total day minutes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b02458",
   "metadata": {},
   "source": [
    "Altair works best with pandas dataframes that are in [long-form](https://altair-viz.github.io/user_guide/data.html#long-form-vs-wide-form-data) or [tidy](https://r4ds.had.co.nz/tidy-data.html) format. The `prepare_dataframe_one_way` function below puts all of the ICE and PDP data into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe_one_way(one_way_data, ice_instances=100):\n",
    "    dfs = []\n",
    "\n",
    "    # loop over the features in one_way_data\n",
    "    for feature, info in one_way_data.items():\n",
    "        # create a dataframe for the PDP line\n",
    "        dfs.append(pd.DataFrame({\n",
    "            'feature': [info.feature] * len(info.values),\n",
    "            'x': info.values,\n",
    "            'y': info.pd,\n",
    "            'kind': ['pdp'] * len(info.values)\n",
    "        }))\n",
    "\n",
    "        # create a dataframe for the ICE lines\n",
    "        dfs.append(pd.DataFrame({\n",
    "            'feature': [feature] * ice_instances,\n",
    "            'x': [info.values for _ in range(ice_instances)],\n",
    "            'y': info.ice[:ice_instances].tolist(),\n",
    "            'kind': ['ice'] * ice_instances\n",
    "        }).explode(['x', 'y']).reset_index())\n",
    "\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = prepare_dataframe_one_way(one_way_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d7eb8",
   "metadata": {},
   "source": [
    "The index column is used to identify which original instance an ICE line represents. If two ICE rows have the same feature and index, then they are a part of the same ICE line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c9493",
   "metadata": {},
   "source": [
    "Here's how we can filter the dataframe to get the PDP line for the \"total day minutes\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed799d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tdm_pdp = df1[(df1['feature'] == 'total day minutes') & (df1['kind'] == 'pdp')]\n",
    "df_tdm_pdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecb72f",
   "metadata": {},
   "source": [
    "Here's how we can filter the dataframe to get all of the ICE lines for the \"total day minutes\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd454342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tdm_ice = df1[(df1['feature'] == 'total day minutes') & (df1['kind'] == 'ice')]\n",
    "df_tdm_ice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c75a949",
   "metadata": {},
   "source": [
    "**Exercise 4:**\n",
    "\n",
    "Using `df_tdm_pdp`, create a PDP for the \"total day minutes\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a5bfb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tdm_pdp = alt.Chart(df_tdm_pdp).mark_line().encode(\n",
    "    x=alt.X('x', title='total day minutes'),\n",
    "    y=alt.Y('y', title='churn probability')\n",
    ")\n",
    "\n",
    "tdm_pdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7716b",
   "metadata": {},
   "source": [
    "**Exercise 5:**\n",
    "\n",
    "Using `df_tdm_ice`, create an ICE plot for the \"total day minutes\" feature. \n",
    "\n",
    "Hint: if you want to have multiple lines all with the same color, then you can use the `detail` encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm_ice = alt.Chart(df_tdm_ice).mark_line(color='#d3d3d3', opacity=0.4).encode(\n",
    "    detail='index',\n",
    "    x=alt.X('x', title='total day minutes'),\n",
    "    y=alt.Y('y', title='churn probability')\n",
    ")\n",
    "\n",
    "tdm_ice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa78bc6",
   "metadata": {},
   "source": [
    "We can then layer the PDP over the ICE plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm_ice + tdm_pdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221dd75",
   "metadata": {},
   "source": [
    "Rather than filtering the dataframe ahead of time, we can also filter the data using `transform_filter`. In the below example, we pass the charts the entire `df1` dataframe and then select the \"total day minutes\" feature and the plot kind using `transform_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228920db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm_pdp = alt.Chart(df1).mark_line().encode(\n",
    "    x=alt.X('x', title='total day minutes'),\n",
    "    y=alt.Y('y', title='churn probability')\n",
    ").transform_filter(\n",
    "    (alt.datum.feature == 'total day minutes') & (alt.datum.kind == 'pdp')\n",
    ")\n",
    "\n",
    "tdm_ice = alt.Chart(df1).mark_line(color='#d3d3d3', opacity=0.4).encode(\n",
    "    detail='index',\n",
    "    x=alt.X('x', title='total day minutes'),\n",
    "    y=alt.Y('y', title='churn probability')\n",
    ").transform_filter(\n",
    "    (alt.datum.feature == 'total day minutes') & (alt.datum.kind == 'ice')\n",
    ")\n",
    "\n",
    "tdm_ice + tdm_pdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc884f",
   "metadata": {},
   "source": [
    "Here's another example where we do the same thing, where we make use of a base plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bf5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(df1).mark_line().encode(\n",
    "    x=alt.X('x', title='total day minutes'),\n",
    "    y=alt.Y('y', title='churn probability')\n",
    ").transform_filter(alt.datum.feature == 'total day minutes')\n",
    "\n",
    "tdm_pdp = base.transform_filter(alt.datum.kind == 'pdp')\n",
    "\n",
    "tdm_ice = base.encode(\n",
    "    opacity=alt.value(0.4),\n",
    "    color=alt.value('#d3d3d3'),\n",
    "    detail='index',\n",
    ").transform_filter(alt.datum.kind == 'ice')\n",
    "\n",
    "tdm_ice + tdm_pdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c3b31",
   "metadata": {},
   "source": [
    "**Exercise 7:**\n",
    "\n",
    "Finish the function below to show all of the plots in a grid. The `show_pdp` and `show_ice` parameters should determine what kind of plots to show. You can assume that either one or both will be true.\n",
    "\n",
    "Hints:\n",
    "- Recall from the end of lab 02 that faceting needs to happen after layering, using the `.facet()` method.\n",
    "- Recall from lab 02 that we can use `resolve_scale()` to control whether the charts' x scales are \"shared\" or \"independent\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_way_grid(df, show_pdp=True, show_ice=True):\n",
    "    base = alt.Chart(df).mark_line().encode(\n",
    "        x=alt.X('x', title=None),\n",
    "        y=alt.Y('y', title='churn probability')\n",
    "    ).properties(\n",
    "        width=175,\n",
    "        height=125\n",
    "    )\n",
    "\n",
    "    pdp = base.transform_filter(alt.datum.kind == 'pdp')\n",
    "\n",
    "    ice = base.encode(\n",
    "        opacity=alt.value(0.4),\n",
    "        color=alt.value('#d3d3d3'),\n",
    "        detail='index',\n",
    "    ).transform_filter(alt.datum.kind == 'ice')\n",
    "    \n",
    "    if show_pdp and show_ice:\n",
    "        chart = ice + pdp\n",
    "    elif show_pdp:\n",
    "        chart = pdp\n",
    "    else:\n",
    "        chart = ice\n",
    "    \n",
    "    return chart.facet('feature', columns=4).resolve_scale(x='independent')\n",
    "    \n",
    "plot_one_way_grid(df1, show_ice=True, show_pdp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae346f",
   "metadata": {},
   "source": [
    "**Exercise 7:**\n",
    "\n",
    "Update the `plot_one_way_grid` so that when you hover over a line in one of the charts, it highlights that same instance in all of the other charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_way_grid(df, show_pdp=True, show_ice=True):\n",
    "    base = alt.Chart(df).mark_line().encode(\n",
    "        x=alt.X('x', title=None),\n",
    "        y=alt.Y('y', title='churn probability')\n",
    "    ).properties(\n",
    "        width=175,\n",
    "        height=125\n",
    "    )\n",
    "\n",
    "    pdp = base.transform_filter(alt.datum.kind == 'pdp')\n",
    "\n",
    "    brush = alt.selection_multi(fields=['index'], empty='none', on='mouseover')\n",
    "    \n",
    "    ice = base.encode(\n",
    "        opacity=alt.value(0.4),\n",
    "        color=alt.condition(brush, alt.value('red'), alt.value('#d3d3d3')),\n",
    "        detail='index',\n",
    "    ).transform_filter(\n",
    "        alt.datum.kind == 'ice'\n",
    "    ).add_selection(brush)\n",
    "    \n",
    "    if show_pdp and show_ice:\n",
    "        chart = ice + pdp\n",
    "    elif show_pdp:\n",
    "        chart = pdp\n",
    "    else:\n",
    "        chart = ice\n",
    "    \n",
    "    return chart.facet('feature', columns=4).resolve_scale(x='independent')\n",
    "    \n",
    "plot_one_way_grid(df1, show_ice=True, show_pdp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9160203",
   "metadata": {},
   "source": [
    "## Two-way Partial Dependence Plots\n",
    "\n",
    "Calculating all of the possible two-way PDPs would take too long, so instead we'll just calculate a few of them individually. We'll use the `TwoWayData` class to store the necessary information about a two-way PDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TwoWayData:\n",
    "    x: FeatureData\n",
    "    y: FeatureData\n",
    "    df: pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a641e208",
   "metadata": {},
   "source": [
    "**Exercise 8:**\n",
    "\n",
    "Finish the `calculate_two_way` function below, which should calculate the data for a two-way PDP for the given pair of features. `TwoWayData.df` will be a dataframe with three columns: x, y, and prediction. Each row of this dataframe is one grid spot in the two-way PDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_two_way(data, model, x_feature, y_feature):\n",
    "    \n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    avg_prediction = []\n",
    "    \n",
    "    for x in x_feature.values:\n",
    "        original_x = data[x_feature.feature]\n",
    "        \n",
    "        data[x_feature.feature] = x\n",
    "\n",
    "        for y in y_feature.values:\n",
    "            original_y = data[y_feature.feature]\n",
    "            \n",
    "            data[y_feature.feature] = y\n",
    "            predictions = model.predict_proba(data)[:,1]\n",
    "            avg_prediction.append(predictions.mean())\n",
    "            \n",
    "            x_val.append(x)\n",
    "            y_val.append(y)\n",
    "            \n",
    "            data[y_feature.feature] = original_y\n",
    "            \n",
    "        data[x_feature.feature] = original_x\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'x': x_val,\n",
    "        'y': y_val,\n",
    "        'prediction': avg_prediction\n",
    "    })\n",
    "    \n",
    "    return TwoWayData(x_feature, y_feature, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_eve_mins = calculate_two_way(\n",
    "    X_train, model,\n",
    "    one_way_data['total day minutes'],\n",
    "    one_way_data['total eve minutes']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3374e87f",
   "metadata": {},
   "source": [
    "**Exercise 9:**\n",
    "\n",
    "Finish the `plot_two_way` function below, which creates a two-way PDP.\n",
    "\n",
    "Hint: The [heatmap example](https://altair-viz.github.io/gallery/simple_heatmap.html) is a useful reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_way(data):\n",
    "    return alt.Chart(data.df).mark_rect().encode(\n",
    "        x=alt.X('x:O', title=data.x.feature, axis=alt.Axis(format='.2f')),\n",
    "        y=alt.Y('y:O', title=data.y.feature, sort='descending', axis=alt.Axis(format='.2f')),\n",
    "        color='prediction',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22993195",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_way(day_eve_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_mins_service_calls = calculate_two_way(\n",
    "    X_train, model,\n",
    "    one_way_data['total day minutes'],\n",
    "    one_way_data['number customer service calls'],\n",
    ")\n",
    "\n",
    "\n",
    "plot_two_way(day_mins_service_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ef7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_mins_vmail = calculate_two_way(\n",
    "    X_train, model,\n",
    "    one_way_data['total day minutes'],\n",
    "    one_way_data['number vmail messages'],\n",
    ")\n",
    "\n",
    "plot_two_way(day_mins_vmail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1581f",
   "metadata": {},
   "source": [
    "### Showing interaction between features\n",
    "\n",
    "See the [Feature Interaction chapter](https://christophm.github.io/interpretable-ml-book/interaction.html) in Molnar's book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b228971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_interaction(two_way_data):\n",
    "    df = two_way_data.df\n",
    "    \n",
    "    df['mean_centered_prediction'] = df['prediction'] - df['prediction'].mean()\n",
    "    \n",
    "    expected = []\n",
    "    \n",
    "    for x in two_way_data.x.mean_centered_pd:\n",
    "        for y in two_way_data.y.mean_centered_pd:\n",
    "            expected.append(x + y)\n",
    "            \n",
    "    df['interaction'] = df['mean_centered_prediction'] - np.array(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interaction(data):\n",
    "    abs_interaction = data.df['interaction'].abs().max()\n",
    "    \n",
    "    return alt.Chart(data.df).mark_rect().encode(\n",
    "        x=alt.X('x:O', title=data.x.feature, axis=alt.Axis(format='.2f')),\n",
    "        y=alt.Y('y:O', title=data.y.feature, sort='descending', axis=alt.Axis(format='.2f')),\n",
    "        color=alt.Color(\n",
    "            'interaction',\n",
    "            scale=alt.Scale(scheme='brownbluegreen', domainMid=0, domain=[-abs_interaction, abs_interaction]),\n",
    "        ),\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4840f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_interaction(day_mins_service_calls)\n",
    "plot_interaction(day_mins_service_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85317d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_interaction(day_eve_mins)\n",
    "plot_interaction(day_eve_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba3c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
