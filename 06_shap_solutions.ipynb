{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7faaed8",
   "metadata": {},
   "source": [
    "# 06: Shapley Values \n",
    "\n",
    "See the sections in Molnar's book on [Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html) and [SHAP](https://christophm.github.io/interpretable-ml-book/shap.html) for background information. For actual use, see the [shap package](https://github.com/slundberg/shap)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aeffc8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmlb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this code locally, this automatically save the chart data in files,\n",
    "# rather than including the data in the spec. You may need to comment this out on Colab.\n",
    "\n",
    "!mkdir -p data\n",
    "alt.data_transformers.enable('json', prefix='data/altair-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea058baa",
   "metadata": {},
   "source": [
    "## Data Preparation and Modeling\n",
    "\n",
    "For this lab, we'll be using a bike rental dataset. This is a regression dataset where the goal is to predict the number of bikes that were rented at a particular day and time. This dataset is from the [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset). The data processing was guided by [Molnar's IML book](https://christophm.github.io/interpretable-ml-book/bike-data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1eb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://gist.githubusercontent.com/DanielKerrigan/f324b392dc9a58d8bd8f8d79e1101a12/raw/c3b4760c9facfac26bcab2cd7465c4cab88ef304/bike-hour.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb57d1",
   "metadata": {},
   "source": [
    "To reduce computation times, we'll drop some of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['yr', 'mnth', 'atemp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b91d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc77501",
   "metadata": {},
   "source": [
    "We'll use the data from 2011 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['days_since_2011'] < 365].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['cnt'])\n",
    "y_train = df_train['cnt'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdc483",
   "metadata": {},
   "source": [
    "Next we'll train a random forest model on this dataset. We'll do a grid search with cross-validation to find reasonable hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10],\n",
    "    'bootstrap': [True],\n",
    "    'max_features': ['sqrt', 1.0],\n",
    "    'max_depth': [6, 12],\n",
    "    'min_samples_split': [2, 8],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1bdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ab01b",
   "metadata": {},
   "source": [
    "## Shapley Implementation\n",
    "\n",
    "**Exercise 1:**\n",
    "\n",
    "First, we will write a function to approximately calculate a feature's Shapley value for a given instance. Our algorithm will be similar to the one that Molnar details in [Section 9.5.3.3](https://christophm.github.io/interpretable-ml-book/shapley.html#estimating-the-shapley-value).\n",
    "\n",
    "*1a)* Select a random instance from the dataframe `df`. [df.sample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html#pandas-dataframe-sample) is useful for this.\n",
    "\n",
    "*1b)* Select a random set of features, not including the feature that we are calculating the shapley value for (`feature`). [random.randint()](https://docs.python.org/3/library/random.html#random.randint) and [random.sample()](https://docs.python.org/3/library/random.html#random.sample) are useful for this.\n",
    "\n",
    "*1c)* Make a copy of the instance `x`. For the features randomly selected in 1b, replace the value in `x` with the value in the random instance from 1a.\n",
    "\n",
    "*1d)* Make a copy of the instance from 1c. Replace the value of `feature` with the value from the random instance from 1a.\n",
    "\n",
    "*1e)* Get the predicted values of the instances from 1c and 1d. Calculate the difference between the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df - dataframe containing the entire dataset\n",
    "x - dataframe containing a single instance\n",
    "model - trained sklearn model\n",
    "feature - the name of the feature that we are computing the Shapley value for\n",
    "iterations - number of iterations to run for\n",
    "'''\n",
    "def calculate_shapley_value(df, x, model, feature, iterations):\n",
    "    # keep track of the total from the summation\n",
    "    value = 0\n",
    "    \n",
    "    # list of features besides the one we are computing the shapley value for\n",
    "    other_features = [f for f in df.columns if f != feature]\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # 1a: get a random instance from the df\n",
    "        random_instance = df.sample()\n",
    "        \n",
    "        # 1b: select a random set of features\n",
    "        num_features_to_change = random.randint(0, len(other_features))\n",
    "        features_to_change = random.sample(other_features, num_features_to_change)\n",
    "        \n",
    "        # 1c: make a copy of the instance x for the randomly selected features,\n",
    "        # replace the value of that feature in x with the value in random_instance\n",
    "        z_original = x.copy()\n",
    "        \n",
    "        for f in features_to_change:\n",
    "            z_original[f] = random_instance[f].values\n",
    "            \n",
    "        # 1d: make a copy of z_original. replace the value\n",
    "        # of feature with the value in random_instance\n",
    "        z_different = z_original.copy()\n",
    "        z_different[feature] = random_instance[feature].values\n",
    "        \n",
    "        \n",
    "        # 1e: get the predicted values for z_original and z_different.\n",
    "        # calculate the difference between them\n",
    "        pred_original = model.predict(z_original)[0]\n",
    "        pred_different = model.predict(z_different)[0]\n",
    "        difference = pred_original - pred_different\n",
    "        \n",
    "        value += difference\n",
    "        \n",
    "    # take the mean\n",
    "    return value / iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_shapley_value(X_train, X_train.iloc[[0]], model, 'hr', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2cfd4",
   "metadata": {},
   "source": [
    "The below `shapley_values` function calculates the shapley value of every feature for every instance in `df`. It returns a dataframe containing the shapley values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f58ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapley_values(df, model, iterations):\n",
    "    rows = []\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        # get a row from the dataframe as a dataframe\n",
    "        x = df.iloc[[i]]\n",
    "        \n",
    "        row = {}\n",
    "        \n",
    "        for feature in df.columns:\n",
    "            row[feature] = calculate_shapley_value(df, x, model, feature, iterations)\n",
    "            \n",
    "        rows.append(row)\n",
    "        \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bd6c4",
   "metadata": {},
   "source": [
    "We'll use a subset of 100 instances from the training set to compute the shapley values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d913687",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = X_train.sample(100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley = shapley_values(subset, model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed64768",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd416426",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f90911",
   "metadata": {},
   "source": [
    "### Feature Importance Bar Chart\n",
    "\n",
    "**Exercise 2:** Create a bar chart that shows the feature importance of each feature based on the shapley values.\n",
    "\n",
    "*2a)* Calculate the mean absolute values for each feature in `shapley`. The [mean](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) and [abs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.abs.html) functions will be useful. We will want a dataframe that has two columns: one for the feature and one for the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae31d105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(shapley.abs().mean()).reset_index()\n",
    "feature_importance.columns = ['feature', 'value']\n",
    "\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9caf999",
   "metadata": {},
   "source": [
    "*2b)* Plot the feature importances in a bar chart. Sort the bars in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0167b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feature_importance).mark_bar().encode(\n",
    "    y=alt.Y('feature').sort('-x'),\n",
    "    x=alt.X('value').title('mean absolute shapley value')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100c92d",
   "metadata": {},
   "source": [
    "### Dependence Scatter Plot\n",
    "\n",
    "**Exercise 3:** For a given feature, we can create a scatterplot that shows the relationship between an instance's value for that feature (x-axis) and its shapley value for that feature (y-axis). This works as an alternative to PDPs. Complete the function below to create a dependence plot for the given feature.\n",
    "\n",
    "*3a)* Create a dataframe containing the feature values and shapley values for the given `feature`. This dataframe should have two columns: feature_value and shapley_value. Each row represents an instance.\n",
    "\n",
    "*3b)* Return a scatterplot of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13311af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dependence(instances, shapley, feature):\n",
    "    # 3a: create a dataframe containing the feature values and shapley values \n",
    "    dependence = pd.DataFrame({\n",
    "        'feature_value': instances[feature],\n",
    "        'shapley_value': shapley[feature]\n",
    "    })\n",
    "    \n",
    "    # 3b: plot the values in a scatterplot\n",
    "    return alt.Chart(dependence).mark_point().encode(\n",
    "        x=alt.X('feature_value').title(feature),\n",
    "        y='shapley_value'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fecb105",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dependence(subset, shapley, 'hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0486e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dependence(subset, shapley, 'temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01aea9e",
   "metadata": {},
   "source": [
    "### Summary Strip Plot\n",
    "\n",
    "We can create a strip plot that shows every individual shapley value. There will be one row for each feature. In each row, there will be one dot for each instance. The x position of each dot will encode the instance's shapley value. The color of each dot will encode the instance's feature value. We will jitter the dots in the y direction to reduce overlap.\n",
    "\n",
    "First, we need to transform our data to get it into a dataframe that looks like the table below. In this dataframe, there will be one row for every feature in every instance.\n",
    "\n",
    "| feature         | shapley_value | feature_value |\n",
    "|-----------------|---------------|---------------|\n",
    "| days_since_2011 | 135.0         | 6.453387      |\n",
    "| days_since_2011 | 198.0         | 2.502707      |\n",
    "| days_since_2011 | 248.0         | 16.331289     |\n",
    "\n",
    "We can use the [melt](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html) function in pandas to help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791dc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dbf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = subset.melt(ignore_index=False)\n",
    "values.columns = ['feature', 'feature_value']\n",
    "values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d3ce5",
   "metadata": {},
   "source": [
    "We can do the same thing for the dataframe that contains shapley values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d39db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values = shapley.melt(ignore_index=False)\n",
    "shapley_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8f09b",
   "metadata": {},
   "source": [
    "Then we can combine our newly created dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d428294",
   "metadata": {},
   "outputs": [],
   "source": [
    "values['shapley_value'] = shapley_values['value']\n",
    "values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd7583a",
   "metadata": {},
   "source": [
    "**Exercise 4:** Using the `values` dataframe, create the strip plot. See the end of 01_altair_questions.ipynb for an example of a strip plot with jittering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d835b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features = feature_importance.sort_values(by='value', ascending=False)['feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafaa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(values).mark_circle().encode(\n",
    "    x='shapley_value',\n",
    "    row=alt.Row('feature')\n",
    "        .sort(sorted_features)\n",
    "        .spacing(0)\n",
    "        .header(labelAngle=0, labelAlign='left'),\n",
    "    y=alt.Y('jitter:Q').axis(None),\n",
    "    color=alt.Color('feature_value')\n",
    "        .scale(scheme='viridis')\n",
    "        .title(None)\n",
    ").properties(\n",
    "    height=50,\n",
    "    width=700\n",
    ").transform_calculate(\n",
    "    jitter='random()'\n",
    ").resolve_scale(\n",
    "    color='independent'\n",
    ").configure_legend(\n",
    "    gradientLength=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b19f9",
   "metadata": {},
   "source": [
    "### Feature Contribution Bar Chart\n",
    "\n",
    "**Exercise 5:** Create a bar chart that shows the feature contribution of each feature for the given instance. The input will be a dataframe that contains the features, feature values, and shapley values for a single instance.\n",
    "\n",
    "Once you have a basic bar chart, try to\n",
    "- sort the bars in descending order of shapley value\n",
    "- color the bars according to whether the shapley value is positive or negative\n",
    "- show the feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "values.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contribution(values):\n",
    "    bars = alt.Chart(values).mark_bar().encode(\n",
    "        y=alt.Y('feature').sort('-x'),\n",
    "        x='shapley_value',\n",
    "        color=alt.condition(alt.datum.shapley_value > 0, alt.value('crimson'), alt.value('steelblue')),\n",
    "        tooltip=['feature', 'feature_value', 'shapley_value']\n",
    "    )\n",
    "    \n",
    "    return bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contribution(values.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contribution(values.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbad05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contribution(values.loc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef4f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contribution(values):\n",
    "    values = values.copy()\n",
    "    \n",
    "    values['is_positive'] = values['shapley_value'] > 0\n",
    "    values['feature_and_value'] = values['feature'] + ' = ' + values['feature_value'].astype(str)\n",
    "    \n",
    "    bars = alt.Chart(values).mark_bar().encode(\n",
    "        y=alt.Y('feature_and_value').sort('-x'),\n",
    "        x='shapley_value',\n",
    "        color=alt.Color('is_positive')\n",
    "            .legend(None)\n",
    "            .scale(range=['steelblue', 'crimson'])\n",
    "    )\n",
    "    \n",
    "    return bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contribution(values.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6feb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contribution(values.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contribution(values.loc[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
